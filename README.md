Sure! Hereâ€™s a clean, professional **README** draft for your GitHub repo that matches the CV description and highlights the key features clearly:

---

# Multi-Modal PDF Query System with RAG and Voice Output

[![GitHub Repo](https://img.shields.io/badge/GitHub-mrinalchaturvedi27/bootcamp-blue)](https://github.com/mrinalchaturvedi27/bootcamp)

---

## Project Overview

This project implements an end-to-end **Retrieval-Augmented Generation (RAG)** system designed to query PDF documents via natural language and get **both text and voice** responses. It combines advanced **PDF content understanding**, **semantic search with vector databases**, **large language models (LLMs)**, and **text-to-speech (TTS)** technologies to create a powerful multi-modal AI assistant.

---

## Features

* **PDF Content Extraction**: Efficiently extracts and chunks content from PDF files using PyMuPDF.
* **Semantic Embeddings & Search**: Uses **nomic-embed-text** and **FastEmbed** to embed document chunks and stores them in vector databases (**FAISS** or **ChromaDB**) for fast semantic retrieval.
* **Retrieval-Augmented Generation**: Integrates with **Ollama LLMs** (Llama 3.2) via **LangChain** to generate accurate and context-aware answers based on retrieved document content.
* **Voice Responses**: Converts AI-generated answers to high-quality natural speech using the **ElevenLabs TTS API**, enabling voice interaction.






